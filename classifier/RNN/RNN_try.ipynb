{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate data\n",
    "# each data is combined of different numbers of element\n",
    "# each element has length of 4\n",
    "# there are two class, class 0 the entries in element are totally radom\n",
    "# class 1 the entries are continuous\n",
    "num_sample = 2000\n",
    "elementLen = 4\n",
    "dataMLen = 12\n",
    "dataset = []\n",
    "label = []\n",
    "seqLen = []\n",
    "for i in range(num_sample):\n",
    "    length = np.random.randint(1, dataMLen + 1)\n",
    "    seqLen.append(length)\n",
    "    # generate random element\n",
    "    if np.random.random() < 0.5:\n",
    "        temp = np.random.randint(1, 100, [length, elementLen])\n",
    "        label.append([1., 0.])\n",
    "    else:\n",
    "        temp = np.array(range(1, length * 4 + 1))\n",
    "        temp = temp.reshape([length, elementLen])\n",
    "        label.append([0., 1.])\n",
    "    temp = np.append(temp, np.zeros([dataMLen - length, elementLen]), axis=0)\n",
    "    dataset.append(temp.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# separate into training dataset and testing\n",
    "ratio = 0.3\n",
    "test_data = dataset[-int(ratio * num_sample):]\n",
    "test_label = label[-int(ratio * num_sample):]\n",
    "test_len = seqLen[-int(ratio * num_sample):]\n",
    "train_data = dataset[:-int(ratio * num_sample)]\n",
    "train_label = label[:-int(ratio * num_sample)]\n",
    "train_len = seqLen[:-int(ratio * num_sample)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set parameter\n",
    "learning_rate = 0.0001\n",
    "batch_size = 128\n",
    "training_iter = 1000\n",
    "display_step = 100\n",
    "hidden_layer = 100\n",
    "classes = 2\n",
    "indices = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# place holder\n",
    "x = tf.placeholder('float', [None, None, elementLen], name='input2')\n",
    "y = tf.placeholder('float', [None, classes], name='label')\n",
    "w = tf.Variable(tf.random_normal([hidden_layer, classes]), name='weights')\n",
    "b = tf.Variable(tf.random_normal([classes]), name='bias')\n",
    "seqlen = tf.placeholder(tf.int32, [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get batch\n",
    "def next_batch(X, Y, length, batch_size = batch_size):\n",
    "    global indices\n",
    "    batch_x = X[indices: indices + batch_size]\n",
    "    batch_y = Y[indices: indices + batch_size]\n",
    "    batch_l = length[indices: indices + batch_size]\n",
    "    indices += batch_size\n",
    "    if indices >= len(X):\n",
    "        indices = indices % len(X)\n",
    "        batch_x.extend(X[: indices])\n",
    "        batch_y.extend(Y[: indices])\n",
    "        batch_l.extend(length[: indices])\n",
    "    return batch_x, batch_y, batch_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define RNN\n",
    "# the inpute size is [batch_size, length, element_size]\n",
    "def RNN(x, seqlen, w, b):\n",
    "    lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(hidden_layer)\n",
    "    outputs, state = tf.nn.dynamic_rnn(lstm_cell, x, seqlen, dtype=tf.float32)\n",
    "    batch_size = tf.shape(outputs)[0]\n",
    "    dataMLen = tf.shape(x)[1]\n",
    "    index = tf.range(0, batch_size) * dataMLen + (seqlen - 1)\n",
    "    output = tf.gather(tf.reshape(outputs, [-1, hidden_layer]), index)\n",
    "    output = tf.nn.softmax(tf.matmul(output, w) + b)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/douzhi/Software/anaconda3/envs/cs505/lib/python3.5/site-packages/tensorflow/python/ops/gradients.py:90: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "# set lose function\n",
    "pred = RNN(x, seqlen, w, b)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# compute the accuracy\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "# check x\n",
    "inp = x\n",
    "\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run network\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(training_iter):\n",
    "        batch_x, batch_y, batch_l = next_batch(train_data, train_label, train_len)\n",
    "#         print(len(batch_x), len(batch_y), len(batch_l))\n",
    "        inp = sess.run(inp, feed_dict={x: batch_x})\n",
    "        break\n",
    "        output=sess.run(optimizer, feed_dict={x: batch_x, y: batch_y, seqlen: batch_l})\n",
    "        \n",
    "        if i % display_step == 0:\n",
    "            acc = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y, seqlen: batch_l})\n",
    "            # Calculate batch loss\n",
    "            loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y, seqlen: batch_l})\n",
    "            print(\"Iter \" + str(i) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc))\n",
    "            \n",
    "#     print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict={x: test_data, y: test_label, seqlen: test_len}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 12, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.shape"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:cs505]",
   "language": "python",
   "name": "conda-env-cs505-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
